{
  "unifiedModelConfiguration": {
    "version": "1.0.0",
    "lastUpdated": "2025-01-12",
    "description": "Unified configuration for maximum model access across all CLI tools and MCP servers",
    
    "availableModels": {
      "claude": {
        "claude-4.5": {
          "provider": "anthropic",
          "cliTools": ["cursor", "claude-code"],
          "mcpServers": ["serena"],
          "capabilities": ["reasoning", "analysis", "architecture"],
          "priority": 1
        },
        "claude-3.5-sonnet": {
          "provider": "anthropic", 
          "cliTools": ["cursor"],
          "mcpServers": ["serena"],
          "capabilities": ["coding", "analysis"],
          "priority": 2
        }
      },
      "openai": {
        "gpt-5-codex": {
          "provider": "openai",
          "cliTools": ["codex", "cursor", "copilot"],
          "mcpServers": ["codex-mcp-server"],
          "capabilities": ["coding", "implementation", "refactoring"],
          "priority": 1,
          "variants": ["low", "medium", "high"]
        },
        "gpt-5": {
          "provider": "openai",
          "cliTools": ["codex", "cursor", "copilot"],
          "mcpServers": ["codex-mcp-server"],
          "capabilities": ["general", "reasoning", "analysis"],
          "priority": 2,
          "variants": ["low", "medium", "high"]
        },
        "gpt-4": {
          "provider": "openai",
          "cliTools": ["codex", "cursor", "copilot"],
          "mcpServers": ["codex-mcp-server"],
          "capabilities": ["general", "coding"],
          "priority": 3
        },
        "gpt-3.5-turbo": {
          "provider": "openai",
          "cliTools": ["codex", "cursor", "copilot"],
          "mcpServers": ["codex-mcp-server"],
          "capabilities": ["general", "fast"],
          "priority": 4
        }
      },
      "google": {
        "gemini-2.5-pro": {
          "provider": "google",
          "cliTools": ["gemini", "cursor"],
          "mcpServers": ["gemini-mcp-tool"],
          "capabilities": ["reasoning", "analysis", "creative"],
          "priority": 1
        },
        "gemini-2.5-flash": {
          "provider": "google",
          "cliTools": ["gemini", "cursor"],
          "mcpServers": ["gemini-mcp-tool"],
          "capabilities": ["fast", "creative", "analysis"],
          "priority": 2
        }
      },
      "xai": {
        "grok-4-code": {
          "provider": "xai",
          "cliTools": ["grok"],
          "mcpServers": [],
          "capabilities": ["coding", "analysis"],
          "priority": 1
        },
        "grok-code-fast-1": {
          "provider": "xai",
          "cliTools": ["grok"],
          "mcpServers": [],
          "capabilities": ["fast-coding"],
          "priority": 2
        }
      },
      "specialized": {
        "cheetah": {
          "provider": "anthropic",
          "cliTools": ["cursor"],
          "mcpServers": ["serena"],
          "capabilities": ["performance", "optimization"],
          "priority": 1
        },
        "code-supernova-1-million": {
          "provider": "anthropic",
          "cliTools": ["cline"],
          "mcpServers": ["serena"],
          "capabilities": ["context", "memory", "integration"],
          "priority": 1
        }
      }
    },
    
    "cliToolConfigurations": {
      "codex": {
        "configFile": "~/.codex/config.toml",
        "availableModels": ["gpt-5-codex", "gpt-5", "gpt-4", "gpt-3.5-turbo"],
        "defaultModel": "gpt-5-codex",
        "authentication": "oauth",
        "status": "authenticated",
        "mcpIntegration": true,
        "commands": {
          "exec": "codex exec --model {model} \"{prompt}\"",
          "interactive": "codex --model {model}",
          "mcp": "codex mcp"
        }
      },
      "gemini": {
        "configFile": "~/.gemini/settings.json",
        "availableModels": ["gemini-2.5-pro", "gemini-2.5-flash"],
        "defaultModel": "gemini-2.5-pro",
        "authentication": "oauth",
        "status": "authenticated",
        "mcpIntegration": true,
        "commands": {
          "exec": "gemini -m {model} -p \"{prompt}\"",
          "interactive": "gemini -m {model}",
          "mcp": "gemini mcp"
        }
      },
      "grok": {
        "configFile": "~/.grok/user-settings.json",
        "availableModels": ["grok-4-code", "grok-code-fast-1"],
        "defaultModel": "grok-4-code",
        "authentication": "api-key",
        "status": "needs-api-key",
        "mcpIntegration": false,
        "commands": {
          "exec": "grok --api-key {api-key} -m {model} \"{prompt}\"",
          "interactive": "grok --api-key {api-key} -m {model}"
        }
      },
      "cursor": {
        "type": "ide-integration",
        "availableModels": ["claude-4.5", "claude-3.5-sonnet", "gpt-5-codex", "gpt-5", "gemini-2.5-pro", "gemini-2.5-flash", "cheetah"],
        "defaultModel": "claude-4.5",
        "status": "active",
        "mcpIntegration": true
      },
      "cline": {
        "type": "ide-integration",
        "availableModels": ["code-supernova-1-million", "claude-4.5"],
        "defaultModel": "code-supernova-1-million",
        "status": "active",
        "mcpIntegration": true
      }
    },
    
    "mcpServerConfigurations": {
      "serena": {
        "status": "active",
        "tools": 18,
        "models": ["claude-4.5", "claude-3.5-sonnet", "cheetah"],
        "capabilities": ["memory", "symbolic-analysis", "code-editing"],
        "priority": 1
      },
      "codex-mcp-server": {
        "status": "active",
        "tools": 4,
        "models": ["gpt-5-codex", "gpt-5", "gpt-4", "gpt-3.5-turbo"],
        "capabilities": ["code-assistance", "session-management"],
        "priority": 2
      },
      "gemini-mcp-tool": {
        "status": "active",
        "tools": 7,
        "models": ["gemini-2.5-pro", "gemini-2.5-flash"],
        "capabilities": ["analysis", "creative", "brainstorming"],
        "priority": 3
      },
      "sequential-thinking": {
        "status": "active",
        "tools": 1,
        "models": ["any"],
        "capabilities": ["structured-reasoning", "problem-solving"],
        "priority": 4
      },
      "jetbrains": {
        "status": "timeout-issues",
        "tools": 13,
        "models": ["any"],
        "capabilities": ["ide-integration", "code-analysis"],
        "priority": 5
      }
    },
    
    "orchestrationSettings": {
      "parallelProcessing": true,
      "maxConcurrentSessions": 5,
      "consensusThreshold": 0.7,
      "autoHandoff": true,
      "sessionPersistence": true,
      "contextSharing": true,
      "modelHierarchy": {
        "tier1": ["claude-4.5"],
        "tier2": ["gpt-5-codex-low", "gpt-5-codex-medium", "gpt-5-codex-high"],
        "tier3": ["cheetah"],
        "tier4": ["code-supernova-1-million"],
        "tier5": ["gpt-5-low", "gpt-5-medium", "gpt-5-high", "gemini-2.5-pro", "gemini-2.5-flash", "grok-4-code"]
      }
    },
    
    "optimizationRecommendations": {
      "immediate": [
        "Configure Grok API key for full XAI model access",
        "Fix JetBrains MCP server timeout issues",
        "Test all MCP server connections",
        "Validate model switching across tools"
      ],
      "enhancement": [
        "Add model performance monitoring",
        "Implement dynamic model selection",
        "Create unified model interface",
        "Add model capability testing"
      ]
    },
    
    "status": {
      "totalModels": 12,
      "activeModels": 10,
      "activeCLITools": 3,
      "activeMCPServers": 4,
      "orchestrationReady": true,
      "parallelProcessing": true
    }
  }
}
